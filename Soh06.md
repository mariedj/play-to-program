Leen-Kiat Soh. 2006. Incorporating an intelligent tutoring system into CS1. In _Proceedings of the 37th SIGCSE technical symposium on Computer science education_ (SIGCSE '06). ACM, New York, NY, USA, 486-490.


They use a Intelligent Learning Materials Agent (ILMDA) that delivers learning material based on the usage history of the learning materials, the student background (GPA, courses taken, major) and a dynamic activity profile (Based on the students interactions with the ITS to date). The agent uses case based reasoning to determine which module to present to a student. Each module consist of an overall question reading materials pertaining to a topic, example problems, and then practice problems. Examples are chosen based on the students profile. The system uses machine learning to determine which problems have been incorrect in terms of difficulty and which teaching strategies have led to success, and thus improves its performance over time.

The meat of the paper is devoted to a test conducted on 9 students of a CS1 class. They use three different versions of their ILMDA program, one as simply a version that displayed problems for students to answer based on the problems difficulty level, a second version with more of a traditional ITS feel giving problems based on past instructional strategies and the system did not have the learning capabilities added in the full version of ILMDA, and a third version with machine learning. At the end of the year they sampled three students from the A range, B range, and C range. Due to the small smaple size, they can not confidently validate their hyptohesis that the ILMDA program directly increases a students performance. However, the students that went through ILMDA problems achieved higher scores, whereas students that did not, achieved lower scores. They also found that students using the machine learning version of ILMDA achieved the same level of difficulty with fewer examples and problems. RD

DJW adds, there appears to be much that is notable about the ILMDA system.  One thing is the adaptable case based reasoning approach that it uses to select examples and questions to present to the user.  Another is how is not only evaluates the students, it evaluates itself and attempts to adapt (using machine learning) to improve its performance by modifying the metadata associated with the materials.  This metadata would normally be static and is initially entered into the system along with the materials themselves by the developer/instructor.  The way the metadata get modified from their initial values can present useful information to the instructor about the quality and difficulty of materials, as well as any other properties or relationships expressed in the system as adaptable metadata.  For the system's self-evaluation to be useful, it needs to be used with a large group of students and connected to a centralized database.  After presenting the student with reading materials, it presents them with examples and problems, after each allowing the student to decide whether or not they want another one.  The main goal of the system is to get the student to answer as high a percentage of problems correctly (including at least one difficult one) while presenting a minimal number of examples and problems.