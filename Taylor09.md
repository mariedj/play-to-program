David Scot Taylor, Andrei F. Lurie, Cay S. Horstmenn, Menko B. Johnson, Sean K. Sharma, and Edward C. Yin. 2009. Predictive vs. passive animation learning tools. In _Proceedings of the 40th ACM technical symposium on Computer science education_ (SIGCSE '09). ACM, New York, NY, USA, 494-498.

Other research has argued that students have to be engaged with visualizations for them to be effective learning tools.  In this papers, the authors argue that simply interacting with a visualization (such as having limited control over it) is not enough for a student to really be engaged.  They propose making the student predict the behavior of the algorithm before seeing the visualization as a way to actively engage the student, and they cite other research that supports this idea.  They conducted their own experiment with tools of both types they had created for graph algorithms.  Students did homework questions on the material in an online system and were given access to one of the tools with each problem.  Through the entire set of problems students would use both tools (so that none ultimately had an advantage over others, which helped with IRB approval) and performance on each question was evaluated.  Their predictive tool actually had two versions; one that would confirm or reject the student's prediction at every step and one that would allow them to work their way through the algorithm before checking their answer as well as allowing the student to undo/backtrack while entering their prediction.  Their results show that "predictive" visualizations were more effective than "passive" ones, but they don't further distinguish between the two versions of the predictive tool.